\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{array}
\usepackage{geometry}
\usepackage{float}
\usepackage{multirow}

\geometry{left=1in, right=1in, top=1in, bottom=1in}

\title{\textbf{Impact of Chunk Size on Information Retrieval Performance: \\ Fixed Token Chunking vs. Kamradt Modified Chunking}}
\author{Your Name(s) \\ Your Institution \\ \texttt{your.email@example.com}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Text chunking plays a crucial role in retrieval-augmented generation (RAG) and information retrieval systems by structuring large text corpora into manageable units for efficient querying. This study investigates the effect of chunk size variation on retrieval performance for two distinct chunking techniques: \textbf{Fixed Token Chunking (syntactic segmentation)} and \textbf{Kamradt Modified Chunking (semantic clustering-based segmentation)}. 

We systematically evaluate these chunking methods across multiple chunk sizes:
\begin{itemize}
    \item \textbf{Fixed Token Chunking}: 512 $\rightarrow$ 256 $\rightarrow$ 128 $\rightarrow$ 64 tokens.
    \item \textbf{Kamradt Modified Chunking}: 400 $\rightarrow$ 200 $\rightarrow$ 100 $\rightarrow$ 50 tokens.
\end{itemize}

Performance is measured using \textbf{Intersection over Union (IoU), Recall, Precision Omega, and Precision Mean}. Our findings reveal:
\begin{enumerate}
    \item Reducing chunk size significantly improves precision (+600\% for Fixed Token Chunking, +670\% for Kamradt Modified Chunking).
    \item Smaller chunks improve alignment with ground truth excerpts (IoU increased by 587\% for Fixed Token Chunking, 656\% for Kamradt Modified Chunking).
    \item Recall remains stable ($\sim$64–70\%) for moderate chunk sizes but declines at the smallest sizes.
\end{enumerate}

These results demonstrate that \textbf{Fixed Token Chunking at 64 tokens (12 overlap) and Kamradt Modified Chunking at 100 tokens} provide the best trade-off between \textbf{precision and recall}. We also discuss potential optimizations, such as \textbf{dynamic overlap tuning}, to mitigate recall loss. 

\textbf{Keywords}: Text Chunking, Information Retrieval, Retrieval-Augmented Generation, Semantic Chunking, Precision, Recall, Chunk Alignment.
\end{abstract}

\section{Introduction}

\subsection{Background and Motivation}
Retrieval-augmented generation (RAG), search engines, and question-answering (QA) systems rely on effective document chunking to \textbf{enhance retrieval accuracy} while preserving semantic coherence. Chunk size selection significantly impacts performance by influencing \textbf{retrieval precision, recall, and relevance}. 

Two primary approaches to chunking exist:
\begin{enumerate}
    \item \textbf{Fixed Token Chunking} – A syntactic method that \textbf{splits text into equal-sized segments with overlap}, widely used due to its \textbf{computational efficiency}.
    \item \textbf{Semantic Chunking} – More advanced techniques like \textbf{Kamradt Modified Chunking} attempt to segment text \textbf{based on semantic similarity}, using \textbf{embedding-based clustering} to maintain topic consistency within chunks.
\end{enumerate}

Despite widespread use, there is \textbf{limited empirical research} comparing how chunk size variations impact retrieval performance in \textbf{structured (Fixed Token) vs. semantic (Kamradt) chunking}. This study systematically evaluates their \textbf{trade-offs across different chunk sizes}, providing insights for \textbf{optimizing retrieval efficiency}.

\section{Methodology}

\subsection{Chunking Techniques Evaluated}
\subsubsection{Fixed Token Chunking}
This method \textbf{splits text at uniform intervals} while allowing \textbf{partial overlap} to retain context. We evaluate:
\begin{itemize}
    \item 512 tokens, 100 overlap
    \item 256 tokens, 50 overlap
    \item 128 tokens, 25 overlap
    \item 64 tokens, 12 overlap
\end{itemize}

\subsubsection{Kamradt Modified Chunking}
This method \textbf{groups semantically similar sentences}, dynamically adjusting boundaries based on \textbf{cosine similarity of embeddings}. We test:
\begin{itemize}
    \item 400 tokens (baseline)
    \item 200 tokens
    \item 100 tokens
    \item 50 tokens
\end{itemize}

\subsection{Experimental Setup}
\begin{itemize}
    \item \textbf{Dataset}: Scientific and chemistry-related texts.
    \item \textbf{Embedding Model}: OpenAI’s \texttt{text-embedding-ada-002}.
    \item \textbf{Retrieval System}: ChromaDB vector store.
    \item \textbf{Evaluation Queries}: Derived from synthetic and human-annotated question sets.
\end{itemize}

\subsection{Evaluation Metrics}
We measure:
\begin{itemize}
    \item \textbf{Intersection over Union (IoU)}: Measures retrieved chunk alignment with reference excerpts.
    \item \textbf{Recall}: Measures how much relevant content is retrieved.
    \item \textbf{Precision Omega}: A stricter measure evaluating how much of the retrieved content is relevant.
    \item \textbf{Precision Mean}: Standard precision measure.
\end{itemize}

\section{Results and Discussion}

\subsection{Fixed Token Chunking Performance}

\begin{table}[H]
\centering
\caption{Retrieval Performance for Fixed Token Chunking}
\begin{tabular}{ccccc}
\toprule
\textbf{Chunk Size} & \textbf{IoU Mean} & \textbf{Recall} & \textbf{Precision Omega} & \textbf{Precision Mean} \\
\midrule
512 tokens  & 0.0134 & 0.6748 & 0.0794  & 0.0134 \\
256 tokens  & 0.0271 & 0.7007 & 0.1464  & 0.0271 \\
128 tokens  & 0.0534 & 0.7089 & 0.2461  & 0.0536 \\
64 tokens   & \textbf{0.0921} & 0.6476 & \textbf{0.3772} & \textbf{0.0938} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Kamradt Modified Chunker Performance}

\begin{table}[H]
\centering
\caption{Retrieval Performance for Kamradt Modified Chunking}
\begin{tabular}{ccccc}
\toprule
\textbf{Chunk Size} & \textbf{IoU Mean} & \textbf{Recall} & \textbf{Precision Omega} & \textbf{Precision Mean} \\
\midrule
400 tokens  & 0.0110 & 0.6629 & 0.0650  & 0.0110 \\
200 tokens  & 0.0194 & 0.6592 & 0.1190  & 0.0194 \\
100 tokens  & 0.0392 & \textbf{0.6933} & 0.2187  & 0.0393 \\
50 tokens   & \textbf{0.0921} & 0.6393 & \textbf{0.3747} & \textbf{0.0847} \\
\bottomrule
\end{tabular}
\end{table}

\end{document}
